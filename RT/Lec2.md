# Informed Search and Local Search

## Informed search:
### Greedy best-first search
+ Evaluation function â„(ğ‘›) (heuristic)
  + estimate of cost from ğ‘› to the closest goal
+ Choose the one with the lowest cost

### A* search
+ Evaluation function ğ‘“(ğ‘›) = ğ‘”(ğ‘›) + â„(ğ‘›)
  + ğ‘”(ğ‘›) = cost so far to reach ğ‘›
  + â„(ğ‘›) = estimated cost to goal from ğ‘›
  + ğ‘“(ğ‘›) = estimated total cost of path through ğ‘› to goal

#### Consistency
+ Most admissible heuristics also have the consistency (monotonicity) property
+ A heuristic is consistent if $â„(ğ‘›)â‰¤ğ‘(ğ‘›, ğ‘, ğ‘›^â€²)+â„(ğ‘›^â€²)$
+ Theorem: If h(n) is consistent, A* using GRAPH-SEARCH is optimal

#### Properties of A*
+ Complete
+ Optimal
+ Time: Exponential in [relative error in â„ Ã— length of soln.]
+ Space: Keeps all nodes in memory

### IDA*
+ A* canÂ beÂ memoryÂ intensive for large problems
+ Iterative deepening A* (Korf, 1985)
+ Iterative deepening iterates on a threshold T
+ Search a node as long as f â‰¤ T
+ Either find a solution (done), or fail, in which case the threshold is increased and a new deph-first search starts

## Local Search
+ In many optimization problems, path is irrelevant; the goal state itself is the solution.
+ Then state space = set of â€œcompleteâ€ configurations;
  + find optimal configuration, e.g., TSP
  + or, find configuration satisfying constraints, e.g., timetable

### Hill-climbing (gradient ascent/descent)
### Simulated annealing
escape local maxima by allowing some â€œbadâ€ moves but gradually decrease their size and frequency