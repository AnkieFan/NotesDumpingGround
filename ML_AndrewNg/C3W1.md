# Course 3 Week 1: Unsupervised learning

## Clustering

### K-means algorithm
+ assign points to cluster centroids
+ find new cluster centroids

#### Implementation:
Repeat{
    &emsp;# assign points to cluster centroids
    &emsp;for i = 1 to m
    &emsp;$c^{(i)}$ := index (from 1 to $K$) of cluster
        &emsp;&emsp;centroid closest to $x^{(i)}$
    &emsp;# Move cluster centroid
    &emsp;for $k$=1 to $K$
        &emsp;&emsp;$\mu_k$ := averange(mean) of points assigned to cluster $k$
}
Distinct: $\min_k ||x^{(i)} - \mu_k||^2$

#### Cost function for K-means
$c^{(i)}$ = index of cluster to which example $x^{(i)}$ is currently assigned
$\mu_k$ = cluster centroid $k$
$\mu_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned 
**Cost function: distortion function**
$J(c^{(1)}, ..., c^{(m)},\mu_1, ..., \mu_K) = \frac{1}{m} \sum^m_{i=1}||x^{(i)} - \mu_k||^2$

#### Random initialization: 
Choose $K < m$
Randomly pick $K$ training examples.
Set $\mu_1, ..., \mu_k$ equal to these $K$ examples.
**Disadvantage and cost function**
![](Img/kmeansinitialization.png)

#### Choosing the value of K
Elbow method(not good):
Use different K to calculate cost function and choose the one with 'Elbow' (decrease from sharply to smoothly)

Evaluate K-means based on a metric for how well it performs for that later/downstream purpose.试多个K值，结合实际用途考虑

## Anomaly detection
### Density estimation
Dataset: ${x^{(1)}, x^{(2)}, ..., x^{(m)}}$
Is $x_{test}$ anomalous?

Model p(x):
+ $p(x_{test}) < \varepsilon$ -> Flag anomaly
+ $p(x_{test}) \geq \varepsilon$ -> "ok"

#### Fraud detection:
$x^{(i)} = $ features of user $i$'s activities
Model $p(x)$ from data.
Identify unusual users by checking which have $p(x) < \varepsilon$

### Gaussian (Normal) distribution
Center of curve: $\mu$
Standard deviation: $\sigma^2$
#### Density estimation
$p(x) = p(x_1; \mu_1,\sigma_1^2)*p(x_2; \mu_2,\sigma_2^2)*p(x_3)*...*p(x_n) = \prod^n_{j=1}p(x_j;\mu_j,\sigma_j^2)$

### Anomaly detection algorithm
1. Choose $n$ features $x_i$ that you think might be indicative of anomalous examples
2. Fit parameters $\mu_1,...,\mu_n, \sigma_1^2,...,\sigma^2_n$
   $\mu_j = \frac{1}{m}\sum^m_{i=1}x_j^{(i)}$
   $\sigma_j^2 = \frac{1}{m}\sum^m_{i=1}(x_j^{(i)}-\mu_j)^2$
3. Given new example x, compute $p(x):$
   $p(x) = \prod^n_{j=1}p(x_j;\mu_j,\sigma_j^2) = \prod^n_{j=1}\frac{1}{\sqrt[2]{2\pi}\sigma_j}\exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$
   Anomaly if $p(x) < \varepsilon$

### Real number evaluation
Training set: 6000 good
CV: 2000 good(y=0), 10 anomalous(y=1)
Test: 2000 good (y=0), 10 anomalous (y=1)

Alternative: (when data set is small, especially anomalous set is small)
Training set: 6000 good
CV: 4000 good, 20 anoalus
NO test set

### Possible evaluation metrices:
- True positive, false positive, false negative, true negative
- Preciasion / Recall
- $F_1$-score

### Choosing featrures
#### Non-gaussian features:
histogram: `plt.hist`
Turn Non-gaussion feature to be gaussion feature: 
+ $\log(x_1)$ -> $x_1$
+ $\log(x_2+C)$ -> $x_2$, where C is a constance
+ $\sqrt{x_3}$ -> $x_3$
+ $x_4^{\frac{1}{3}}$ -> $x_4$

#### Error analysis for anomaly detection
when
+ $p(x) \geq \varepsilon$ large for normal examples x
+ $p(x) < \varepsilon$ large for normal examples x  
 
Most common problem: $p(x)$ is comparable (say, both large) for normal and anomalous examples
E.g.: $x_1, x_2, x_3, x_4$
And it still cannot detecte completely.
Try: $x_5 = \frac{x_3}{x_4}$, $x_6 = \frac{x_3^2}{x_4}$

## Anomaly detection vs. Supervised learning
Anomaly detection | supervised learning
---|---|
Small number of positive examples(y=1) and Large number of negative(y=0) exaples|Large number of positive and negative exaples
Con:Many different "types" if abinakues. It's hard to recognize, feature anomalies may look nothing like any of the anomalous examples.|Enough positive examples for algorithm to get a sense of positive examples are like, feature positive examples likely to be similar to ones in trainging set.
e.g.: Fraud detection|e.g.: Email spam classification
