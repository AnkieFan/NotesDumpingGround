# Course 1 Week 1

## Machine Learning Algorithms
- Supervised Learning
- Unsupervised learning
- Recommender systems
- Reinforcement Learning 

## Supervised Learning
X     ->       Y
input -> output label
+ Learns from data **labeled** with the "right answers" (correct label)
+ X & Y mapping

Examples:
### Regression problem
Any results 
+ Predict a **number**
+ **Infinitely** many possible outputs


### Classification problem
Only certain possible results
+ Predict **categories** (Non-numerical)
+ Find boundaries]

## Unsupervised Learning
Find something interesting in **unlabeled** data
Find **structure** in the data

+ Clustering: Group similar data points together
+ Anomaly detection: Find unusual data points
+ Dimensionality reduction: Compress data using fewer numbers

## Regression Model

### Linear Regression
A supervised learning model

Notation:
*x* = 'input' variable / feature
*y* = 'output'/'target' variable
*y^* (y-hat) = estimate/prediction for output
*m* = number of training examples
*(x, y)* = single training example

### Training process:
+ training set (features, target)
+ Learning Algorithm
+ *x* -> *f* (function/hypothesis) -> *y-hat*
+ feature         model            prediction
e.g.: house price calculation: size -> *f* -> price

### Linear Regression model
$f_{w,b}(x) = wx + b$
$y-hat = f_{w,b}(x)$
+ *w, b*: parameters/coefficients/weights
+ **Univariate**: one variable

### Cost function
Compare prediction ***y-hat*** to the target ***y*** (Error)
e.g.: Squared error cost function (suitable for linear regression)
+ $J_{(w, b)} = \frac{1}{2m}\sum_{i=1}^m(f_{w,b}(x^{(i)})-y^{(i)})^2$
+ Find w, b to make $J_{(w, b)}$ small -> $minimize J_{(w, b)}$ 
+ Squared error cost function is always bowl shape

## Gradient Descent
$w = w - \alpha \frac{\sigma}{\sigma\omega}J(w,b)$

## Code in python

### Lab: Model representation
Train set: `x_train = np.array([1.0, 2.0])`
`.shape`: . Numpy arrays have a `.shape` parameter. `x_train.shape` returns a python tuple with an entry for each dimension. `x_train.shape[0]` is the length of the array. (or just `len(x_train)`)
`scatter()` in `matploylib` library: plot the data points
