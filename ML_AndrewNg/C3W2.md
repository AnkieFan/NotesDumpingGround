# Course 3 Week 2: Recommender System

## Notations
E.g.: Predicting Movie Ratings
+ $n_u$ = no. of users
+ $n_m$ = no. of movies
+ 
+ $n$ feature
+ $x^{i}$ feature vector for movie i
+ $r(i,j) = 1$ if user j has rated movie i
+ $y^{(i,j)}$ = rating given by user j to movie i (defined only if $r(i,j) = 1$)

E.g.: Predict rating for movie $i$ as: $w·x^{(i)} + b$
+ $w^{(j)}, b^{(j)}$ = parameters for user j

## Cost function:
Predict rating: $w^{(j)}·x^{(i)} + b^{(j)}$
$m^{(j)}$ = no. of movies rated by user $j$
#### To learn $w^{(j)}, b^{(j)}$: (mean squared error criteria with regularization)
$\min_{w^{(j)}, b^{(j)}}J(w^{(j)}, b^{(j)}) = \frac{1}{2m^{(j)}}\sum_{i:r(i,j)=1}(w^{(j)}·x^{(i)} + b^{(j)}-y^{(i,j)})^2 + \frac{\lambda}{2m^{(j)}}\sum^n_{k=1}(w_k^{(j)})^2$
#### Since $m^{(j)}$ is a constant, we can simplfy it as:
$\min_{w^{(j)}, b^{(j)}}J(w^{(j)}, b^{(j)}) = \frac{1}{2}\sum_{i:r(i,j)=1}(w^{(j)}·x^{(i)} + b^{(j)}-y^{(i,j)})^2 + \frac{\lambda}{2}\sum^n_{k=1}(w_k^{(j)})^2$
#### To learn parameter $w^{(1)} b^{(1)}, ..., w^{(n_u)} b^{(n_u)}$:
$\frac{1}{2}\sum^{n_u}_{j=1}\sum_{i:r(i,j)=1}(w^{(j)}·x^{(i)} + b^{(j)}-y^{(i,j)})^2 + \frac{\lambda}{2}\\sum^{n_u}_{j=1}sum^n_{k=1}(w_k^{(j)})^2$